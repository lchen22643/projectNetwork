---
title: "math495"
author: "LeiChen"
date: "December 4, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## R Markdown
```{r}
load("doctornet.Rdata")
require(igraph)
library(tidyverse)
library(magrittr)
library(dplyr)
library(RColorBrewer)
```

```{r}
par(oma = c(5,4,0,0) + 0.1, mar = c(0,0,1,1) + 0.1) # margin settings
plot(docnet2,vertex.size=0.3,edge.arrow.size=0.1, vertex.color="blue", vertex.frame.color=NA,xlim=c(-1,1),ylim=c(-1,1))
```

* The simple network visualization of 6: docnet2.(plot 1.1)

#Q1

> Compute some basic statistics about this graph. How many vertices and edges does it have? What is the mean degree? Show a histogram of the degree 


```{r}
Edgenum = length(E(docnet2)$type)
typez = unique(E(docnet2)$type)
docname = length(unique(V(docnet2)$name))
hist(degree(docnet2),main=' distribution of degrees for each vertices')

meandeg = mean(degree(docnet2))
mediandeg = median(degree(docnet2))
largedegvertice =tail(sort(degree(docnet2)),5)

smalldegvertice = head(sort(degree(docnet2)),5)

```

*Based on the distribution of degree plot, we can say the network of doc2 is a scale free distribution network. Because there exist some point that connect more than 50 connection. 

*There are`r docname` different doctors and `r Edgenum` edges consist of 4 difference types (`r typez`) connection between different edges. The following histogram shows the degree. The average degree of the data is `r meandeg` and the median degree of the data is `r mediandeg`.

*By the histogram we can see most of vertices have a degree less than 30. I highlight those vertices which have degree larger than 30 is because it may helpful for different comparision for algorithms of components clustering in following questions.
The top5 nodes of largest degree are: `r largedegvertice`.

*also, there are 5 nodes of smallest degree: `r smalldegvertice`.

```{r}

hist(degree(docnet2, mode="out"),main=' distribution of out-degrees for each vertices')
mean(degree(docnet2, mode="out"))
hist(degree(docnet2, mode="in"),main=' distribution of in-degrees for each vertices')
mean(degree(docnet2, mode="in"))
```

* Moreover, I also sepaerate the degrees to out-degree and in-degree, the average of in-degree and out-degree are both around 6.5, as we seen in out-degree histograms it is very balanced distribution of degree, but the gap between the maximium and the minimum for in-degrees are as huge as 40+. Based on this graph we can get a conclusion: there have some vertices have a very large in-degree and that makes them have a large degree in total.


#Q2

```{r}
components(docnet2)
```

*this outputs shows that, every vertice in this dataset should connect at least one another vertice. By this information we can see that the components way is not very suitable to this data. Based on the basic visualization of docnet2, plot 1.1, the plot should have more components.


> Perform community detection in this graph using Newman's eigenvector method. You should consider the graph to be undirected (use as.undirected).

```{r}
library(igraph)
Newmanclust= cluster_leading_eigen(graph=as.undirected(docnet2), steps = -1, weights = NULL, start = NULL, options = arpack_defaults, callback = NULL, extra = NULL, env = parent.frame())

table(Newmanclust$membership, V(docnet2)$nodeCity) 
```

*The modularity of this data is `r Newmanclust$modularity`, which means this clustering get a pretty well classification( by the large modularity). Modularity is the value to identify which clustering algorithm fits best, its range is [-1,1]. Usually, if mudularity is larger than 0.3, it means the community detection could indicate significant community structure. (the range of modularity is from: https://en.wikipedia.org/wiki/Modularity_(networks))

*In the confusion matrix we can see the Newmans of only get 4 misclassification points, those points may be the connection point for the city they suppose to cluseterd and the components of it been claddified. The largest city (1:Peoria) have been separated to two community, we will keep our eyes on the following problems from this saparate.


>Compare the communities you find to the nodeCity vertex attribute, using a confusion matrix (or any appropriate table). Plot the network, illustrating the results of your community detection with vertex colours. What do you notice?


```{r}
library(igraph)
library(RColorBrewer)

membership<-V(docnet2)$nodeCity
mem.col<-rainbow(length(unique(membership)),alpha=0.3)
V(docnet2)$color<-mem.col[membership]
plot( Newmanclust,as.undirected(docnet2),vertex.color=V(docnet2)$color,edge.width=E(docnet2)/1000000000,Vertex.frame.color = NA)
legend("topleft",legend= unique(V(docnet2)$nodeCity),col=mem.col, title="dottype", text.font=4, bg='lightblue',pch=20,pt.cex=2,cex=1.5,horiz=F)#the color will looks a lot different because the colored shadow of different community
```

* I did not remove vertex labels because when this plot is large enough we can see which points are the connection between different communities. 
* Also, the weakness of Newman eigenvector method is, it is looks messily by the algorithm separated a city to two different communities.

>Compare and contrast communities found by the eigenvector method, those found with walktrap, and the nodeCity attribute.

```{r}
library(igraph)
walkcluster = cluster_walktrap(docnet2)
table(walkcluster$membership, V(docnet2)$nodeCity) 

plot( walkcluster,as.undirected(docnet2),vertex.color=V(docnet2)$color,edge.width=E(docnet2)/1000000000,Vertex.frame.color = NA)
legend("topleft",legend= unique(V(docnet2)$nodeCity),col=mem.col, title="dottype", text.font=4, bg='lightblue',pch=20,pt.cex=2,cex=1.5,horiz=F)#the color will looks a lot different because the colored shadow of different community

```

*The modularity of this data is 0.64, this clustering get a pretty well classificationas well.Also, the benefit of walkcluster is there are not classification problem like Newman's eigenvector algorithm. 
*For now, eventhough walkcluster separate more community, but it could show the good boundary by different community.


#Q3

>We discussed a number of different centrality measures in class. Use these, or some of these, to identify the best set of vertices which, when removed, will disrupt the network.

>Test your results: remove some vertices and test to what extent they disconnect the network.
>Illustrate your results with one or more plots.

*There are some different ways to find the "important points", in this project I will compare closeness cerntrality, betweenness centrality, PageRank, and high degree vertices set, such as largedegvertice. Each way I removed 5 heaviest nodes to do a obeservation of the graph sensitivity and robustness.

*largedegvertice: it just the group of vertices that have largest degree. There are 5 vertices have larger or equal than 30 degree in this network.

```{r}
largedegvertice
g<- docnet2 - V(docnet2)[largedegvertice]
summary(g)#had removed 86 edges and 5 vertices
(Newmang= cluster_leading_eigen(graph=as.undirected(g), steps = -1, weights = NULL, start = NULL, options = arpack_defaults, callback = NULL, extra = NULL, env = parent.frame()))

table(Newmang$membership, V(g)$nodeCity) 
plot( Newmang,as.undirected(g),vertex.color=V(g)$color,edge.width=E(g)/1000000000,Vertex.frame.color = NA)

legend("topleft",legend= unique(V(g)$nodeCity),col=mem.col, title="dottype", text.font=4, bg='lightblue',pch=20,pt.cex=2,cex=1.5,horiz=F)#the color will looks a lot different because the colored shadow of different community
(walkg = cluster_walktrap(g))
table(walkg$membership, V(g)$nodeCity) 
plot( walkg,as.undirected(g),vertex.color=V(g)$color,edge.width=E(g)/1000000000,Vertex.frame.color = NA)
legend("topleft",legend= unique(V(docnet2)$nodeCity),col=mem.col, title="dottype", text.font=4, bg='lightblue',pch=20,pt.cex=2,cex=1.5,horiz=F)#the color will looks a lot different because the colored shadow of different community
```

* I do a comparative by Newman eigenvector method and walktrap. Since I removed the large degree nodes, the modularity of newman eigenvector method becomes 0.65, and it is still been spearate 5 groups. The modularity of new graph by walktrap is increased to 0.66, the separate of walktrap is still 7 communities. Since the output and plot of walktrap is not as good (I mean, the plot starts have some overlapping), walktrap seems more sensitive than Newman eigenvector method.

```{r}
closene = closeness(docnet2, vids = V(docnet2), mode = c("out", "in", "all", "total"),
  weights = NULL, normalized = FALSE)
closeneV = tail(sort(closene),5)


g1<- docnet2 - V(docnet2)[c(73,128,71,124,142)]
summary(g1)#been removed 41 edges by removed 5 vertices
(Newmang1= cluster_leading_eigen(graph=as.undirected(g1), steps = -1, weights = NULL, start = NULL, options = arpack_defaults, callback = NULL, extra = NULL, env = parent.frame()))

table(Newmang1$membership, V(g1)$nodeCity) 
plot( Newmang1,as.undirected(g1),vertex.color=V(g1)$color,edge.width=E(g1)/1000000000,Vertex.frame.color = NA)
legend("topleft",legend= unique(V(g1)$nodeCity),col=mem.col, title="dottype", text.font=4, bg='lightblue',pch=20,pt.cex=2,cex=1.5,horiz=F)#the color will looks a lot different because the colored shadow of different community
(walkg1 = cluster_walktrap(g1))
table(walkg1$membership, V(g1)$nodeCity) 

plot( walkg1,as.undirected(g1),vertex.color=V(g1)$color,edge.width=E(g1)/1000000000,Vertex.frame.color = NA)
mem.col
legend("topleft",legend= unique(V(g1)$nodeCity),col=mem.col, title="dottype", text.font=4, bg='lightblue',pch=20,pt.cex=2,cex=1.5,horiz=F)#the color will looks a lot different because the colored shadow of different community

```
*Closeness cerntrality: Since closeness centrality is reciprocal of the average distance for direction to every other points in this network, as the output value larger, the better closeness centrality have for this point.
* Based on this idea we pick the largest 5 `r closeneV` of the overview.

*This time, since I removed top5 closenss cerntrality points, the modularity of newman eigenvector method becomes 0.64, and it is still been spearate 5 groups. The modularity of new graph by walktrap is increased to 0.66, the separate of walktrap becomes 9 communities. I think walktrap will make people confused by separating too much communities, it is a kind of overfitting.

```{r}
betweene = betweenness(docnet2)
betweeneV = tail(sort(betweene),5)

g2<- docnet2 - V(docnet2)[c(79,189,95,30,212)]
summary(g2)#105 edges been removed
(Newmang2= cluster_leading_eigen(graph=as.undirected(g2), steps = -1, weights = NULL, start = NULL, options = arpack_defaults, callback = NULL, extra = NULL, env = parent.frame()))

table(Newmang2$membership, V(g2)$nodeCity) 
plot( Newmang2,as.undirected(g2),vertex.color=V(g2)$color,edge.width=E(g2)/1000000000,Vertex.frame.color = NA)
legend("topleft",legend= unique(V(g2)$nodeCity),col=mem.col, title="dottype", text.font=4, bg='lightblue',pch=20,pt.cex=2,cex=1.5,horiz=F)#the color will looks a lot different because the colored shadow of different community

(walkg2 = cluster_walktrap(g2))
table(walkg2$membership, V(g2)$nodeCity) 

plot( walkg2,as.undirected(g2),vertex.color=V(g2)$color,edge.width=E(g2)/1000000000,Vertex.frame.color = NA)
legend("topleft",legend= unique(V(g2)$nodeCity),col=mem.col, title="dottype", text.font=4, bg='lightblue',pch=20,pt.cex=2,cex=1.5,horiz=F)#the color will looks a lot different because the colored shadow of different community
```

* Betweeness centrality: the basic idea of betweeness centrality is to find the shortest path for i,and j(all i,j are belong to the graph, i!=j)
* Based on this idea we pick the largest 5 `r betweeneV` of the overview.
* Since I removed top5 heavy betweeness centrality nodes, the modularity of newman eigenvector method is 0.64, and it is still been spearate 5 groups. The modularity of new graph by walktrap is still 0.64, the separate of walktrap increased to 10 communities. But since the walktrap give a less overlapping plot than Newman eigenvector algorithm, walktrap seems more powerful and accuracy than newman eigenvector.

```{r}
pagrank= page.rank(docnet2)
pagrankV = tail(sort(pagrank$vector),5)


g3<- docnet2 - V(docnet2)[c(213,36,212,122,29)]
summary(g3)#194 edges has been removed by those 5 nodes
(Newmang3= cluster_leading_eigen(graph=as.undirected(g3), steps = -1, weights = NULL, start = NULL, options = arpack_defaults, callback = NULL, extra = NULL, env = parent.frame()))

table(Newmang3$membership, V(g3)$nodeCity) 
plot( Newmang3,as.undirected(g3),vertex.color=V(g3)$color,edge.width=E(g3)/1000000000,Vertex.frame.color = NA)
legend("topleft",legend= unique(V(g3)$nodeCity),col=mem.col, title="dottype", text.font=4, bg='lightblue',pch=20,pt.cex=2,cex=1.5,horiz=F)#the color will looks a lot different because the colored shadow of different community
(walkg3 = cluster_walktrap(g3))

table(walkg3$membership, V(g3)$nodeCity) 

plot( walkg3,as.undirected(g3),vertex.color=V(g3)$color,edge.width=E(g3)/1000000000,Vertex.frame.color = NA)
legend("topleft",legend= unique(V(g3)$nodeCity),col=mem.col, title="dottype", text.font=4, bg='lightblue',pch=20,pt.cex=2,cex=1.5,horiz=F)#the color will looks a lot different because the colored shadow of different community
```

* PageRank (via:http://snap.stanford.edu/mlg2013/slides/gleich.pdf) : The basic idea of page rank is that, if a webpage had been click more times, then this webpage will get heavier weights. Based on this ideas, people found that if a weblink had been connected to many popular links, the weblink would get a heavy weight link as well. 
* the sum of the rank 1, and I choose top 5 highest rank points: `r pagrankV` 
* Since I removed top5 heavy weight nodes by PageRank algorithm, the modularity of newman eigenvector method decreased to 0.57, and it is still been spearate 6 groups. Eventhough the modularity of new graph by walktrap is increased to 0.65, walktrap has been separate to 12 communities. 

*So my conclusion of this comparision, I think PageRank would change most of the graph by same points. The limitation of Newman eigenvector method is that it will give a upperbound of the size of communities, based on the size of Newman eigenvector methods' result is always 5 almost same size communities, but if the data is a set of equal size communities, Newman method will be very robustness.
* The strength of Walktrap is it always have high modularity which means the communities are harder to overlapping by walktrap algorithm. But the weakness of walktrap is it is weak if we remove some high degree or heavy weight nodes. It is more fluently in different graphs.

#Q4

>I have written a program to simulate the spread of information on a network in igraph format. Since the spread of information can be modelled as the spread of an "infection" from which you don't recover (once you have the information you don't forget it!), we use the language "infected" to describe nodes that have seen the information.

>My functions are provided in the doctornet.Rdata file along with the network. The function simEpi has 4 arguments: the graph (in igraph format), the initially infected nodes, the probability that an edge transmits the information (per unit time) and the maximum time of the simulation.

>simEpi returns a list with items: results, numInfections and timeToInfection. The results item is a "tibble" (which works very much like a data frame), giving the time, whether each node was infected at that time, and the node's ID. The numInfections entry is a data frame with time and the number of nodes infected at that time. The timeToInfection entry is a tibble with the node id, the time that node was infected and its degree. You will, by this point in the project, also have the computed other quantities about the nodes.

>Here is a quick demonstration of how to use simEpi. NOTE that if you have loaded the MASS package you will need to detach it with detach("packages:MASS").

>And here is a demonstration of how to use my plotting function in combination with the results of simEpi. The first input is the graph. The second input is the results of simEpi. the final input is a list of a few times for which you would like to make the plot. This function plots the graph, colouring vertices according to whether they are "infected" (with the information).
>If you would like to see the function, just type its name without the brackets, eg simEpi or plotInfTimeGraph.

>Explore which kinds of nodes tend to get exposed to the new information earlier, and which kinds of nodes get exposed later. You can use your answers to Q3 to decide what you mean by kinds of nodes. (Clearly, the nodes you set as initially infected are infected first; this is a trivial observation and is not the answer to the question).`

>Discuss your results.

```{r}
mytestlarge<- simEpi(docnet2, init_infected = largedegvertice, inf.prob = 0.5, max.time = 3000)
mytestcenter<- simEpi(docnet2, init_infected = c(73,128,71,124,142), inf.prob = 0.5, max.time = 3000)
mytestbetween<- simEpi(docnet2, init_infected = c(79,189,95,30,212), inf.prob = 0.5, max.time = 3000)
mytestPGRank<- simEpi(docnet2, init_infected = c(213,36,212,122,29), inf.prob = 0.5, max.time = 3000)
mytestsmall<- simEpi(docnet2, init_infected = smalldegvertice, inf.prob = 0.5, max.time = 3000)


```

*So I compared the vertices set from "top5" large degree, "top5" imoprtant closeness centrality, "top5" imoprtant betweeness centrality, "top5" imoprtant Page rank high weights dots.
* I also bring the following line chart to get the speed of, at the same degree and same time, which give the fastest speed of diffusion. Based on the plot we can always seen that the pagerank and betweeness centrality method will find the dots which get the faster speed than other method, also, if a information starts at a small degree of vertices then it may get lower speed of spread at the beginning, but the speed of diffusion will growing while the information send to some powerful and important nodes.

```{r}
mytestlarge$numInfections$type<- rep("largedeg",3000)
mytestcenter$numInfections$type<- rep("center",3000)
mytestbetween$numInfections$type<- rep("between",3000)
mytestPGRank$numInfections$type<- rep("PGRank",3000)
mytestsmall$numInfections$type<- rep("smalldeg",3000)

df = as.data.frame(rbind(mytestlarge$numInfections,mytestbetween$numInfections,mytestcenter$numInfections,mytestPGRank$numInfections,mytestsmall$numInfections))
 ggplot(df, aes(x=t, y=n.infected, group=type, colour=type ) ) + geom_line(size=2)
```

```{r} 
plotInfTimeGraph(docnet2,mytestlarge,c(1,100, 1000,3000))#this is the time plot of large degree  
plotInfTimeGraph(docnet2,mytestcenter,c(1,100,1000,3000))#this is the time plot of closeness centrality 
plotInfTimeGraph(docnet2,mytestbetween,c(1,100,1000,3000))#this is the time plot of betweeness centrality
plotInfTimeGraph(docnet2,mytestPGRank,c(1,100,1000,3000))#this is the time plot of Page Rank method
plotInfTimeGraph(docnet2,mytestsmall,c(1,100,1000,3000))#this is the time plot of smallest degree of vertices

```

*Since the PlotInfTimeGraph() cannot been add the title, I will add the annotation by description. Both of them are followed :top left:mytimes=1, top right:mytimes=100, bottom left: mytimes=1000, bottom right: mytimes=3000.
* Those plots are showing at that time, how the network looks like in diffusion.

#Q5

>Use the network to improve our understanding of why some doctors prescribed the drug early and others did not (if this is possible!). The vertex attribute nodeAdoptionDate has units of months, with 98 or 99 given to doctors who did not prescribe the drug at all.

>You may wish to refer to the dataset descriptions (linked above). You can combine ideas from Q3 and Q4, use your own ideas, and you can use the tools from Part 1 of the course.

>You may wish to read what I think is the first paper on this dataset (in any case it is an early paper about it!): Coleman, J.S., Katz, E. and Menzel, H. (1957), The diffusion of an innovation among physicians. However, do not simply imitate their analysis; add your own, modern, perspective, calculations and plots.

* I draw a pie chart and the outcome 98 and 99 are "no prescription found" and "no prescription data obtained". (Actually the description of the reference reading links are messy, there were no outcome 99 in adoption date, but since the data have a very large amount of "99" in variable AdoptionDates, I would just simply mention it is "no prescription data obtained").
![The screenshots of docnet2 data description](Capture.png)

(this plot is in the directory of my computer I just want to give the description of variable : AdoptionDate)

```{r}

pie(table(V(docnet2)$nodeAdoptionDate),main="outcome distribution of adoption date")
```




```{r}
#Real doctors data get the earliest medicine
real = V(docnet2)[V(docnet2)$nodeAdoptionDate==1]
mytestreal<- simEpi(docnet2, init_infected = real, inf.prob = 0.5, max.time = 3000)
mytestreal$numInfections$type<- rep("realdoctors",3000)
plotInfTimeGraph(docnet2,mytestreal,c(1,100,1000,3000))

dfa = as.data.frame(rbind(mytestreal$numInfections,mytestPGRank$numInfections,mytestsmall$numInfections))
 ggplot(dfa, aes(x=t, y=n.infected, group=type, colour=type ) ) + geom_line(size=2)
```

* This time, by the adoption date I pick 11 doctors who AdoptionDate==1, which means the adoption date of them is November 1953, the earliest time. I draw the compariative plot for the trend of diffusion of real estimates with PageRank method and small degree. Because I think eventhough the real doctors begin for 11 vertices and two other starts at 5 nodes,those two methods outcomes still could give some reference for comparative.
* By this plot we can see that the real doctors infectation is diffused very slow.
